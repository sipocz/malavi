{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malavi_LSTM_KAGGLE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLBntCGbEiQMn+i5nAsiyS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/malavi/blob/B20210507/Malavi_LSTM_KAGGLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDIEMsyet7gl",
        "outputId": "ea89a342-d43d-4d2a-ca0d-f71d9f670ad3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.backend import clear_session"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_d3seQOumaR",
        "outputId": "feff3879-2d6e-4892-a77d-ebde4087b27b"
      },
      "source": [
        "!rm Train.csv\n",
        "fname=\"https://github.com/sipocz/malavi/raw/ccefa7562b0a115d207a02f2cf2754406870ef52/Train.csv\"\n",
        "!wget https://github.com/sipocz/malavi/raw/ccefa7562b0a115d207a02f2cf2754406870ef52/Train.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Train.csv': No such file or directory\n",
            "--2021-05-07 17:13:04--  https://github.com/sipocz/malavi/raw/ccefa7562b0a115d207a02f2cf2754406870ef52/Train.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sipocz/malavi/ccefa7562b0a115d207a02f2cf2754406870ef52/Train.csv [following]\n",
            "--2021-05-07 17:13:05--  https://raw.githubusercontent.com/sipocz/malavi/ccefa7562b0a115d207a02f2cf2754406870ef52/Train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3158546 (3.0M) [text/plain]\n",
            "Saving to: ‘Train.csv’\n",
            "\n",
            "Train.csv           100%[===================>]   3.01M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-07 17:13:05 (89.4 MB/s) - ‘Train.csv’ saved [3158546/3158546]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEn9rS2butAD"
      },
      "source": [
        "df=pd.read_csv(\"Train.csv\",sep=\",\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XushE4muuXn"
      },
      "source": [
        "c_df=[]\n",
        "for i in range(len(df)):\n",
        "    c_df.append(df.Text[i].replace(\",\",\"\").replace(\".\",\"\").replace(\"?\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"!\",\"\").replace(\";\",\"\").replace(\"\\n\",\"\").replace(\":\",\"\").replace(\"<\",\"\").lower())\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0TBBax60Aol"
      },
      "source": [
        "df[\"post\"]=c_df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI4_9w0i-Ua9"
      },
      "source": [
        "labels=['SOCIAL ISSUES', 'EDUCATION', 'RELATIONSHIPS', 'ECONOMY', 'RELIGION', 'POLITICS', 'LAW/ORDER', 'SOCIAL', 'HEALTH', 'ARTS AND CRAFTS', 'FARMING', 'CULTURE', 'FLOODING', 'WITCHCRAFT', 'MUSIC', 'TRANSPORT', 'WILDLIFE/ENVIRONMENT', 'LOCALCHIEFS', 'SPORTS', 'OPINION/ESSAY']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad2cJ8cl-ZTk"
      },
      "source": [
        "label_index=[]\n",
        "for i in list(df.Label):\n",
        "    label_index.append(labels.index(i))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NK5x8m-cYb"
      },
      "source": [
        "df[\"label_index\"]=label_index"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "zLEAmQPY01jD",
        "outputId": "33923205-3545-48a8-f3ba-78b8821feeb6"
      },
      "source": [
        "df.post[1435]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' pac iunguza za boma la chifedulo nthumwi zomwe zimakumana mumzinda wa blantyre kukambirana za nkhani yakuti zigawo za dziko lino zizikhala ndi mtsogoleri wakewake pansi pa mtsogoleri wa dziko zati nkhaniyi kuti iyende bwino mpofunika kusintha malamulo ena mfundoyi ikugwirizana ndi zomwe adanena mphunzitsi wa za ndale kusukulu ya ukachenjede ya chancellor college blessings chinsinga kuti popanda kuunika malamulo nkhaniyi ikhoza kudzetsa chisokonezo  chisale watuluka nkumangidwanso  sipakala waimitsa nyumba ya malamulo  chakwera akwanitse malonjezohrdc choyamba tiunike kuti malamulo athu akutinji chifukwa mukhoza kukhala ndi zigawo zodziyimira pazokha zomwe zingamakolanenso chifukwa cha malamulo omwe mukutsata adatero chinsinga msonkhanowo udakonzedwa ndi bungwe la mipingo la public affairs committee pac ndipo cholinga chake chidali kuunika chomwe chidayambitsa nkhaniyi ndi kukambirana momwe ingayendere malinga ndi wapampando wa bungwe la pac mbusa felix chingota nthumwi za kumsonkhanowo zidapeza kuti nkhaniyo idachokera pakusamvetsetsana pa momwe zinthu zina zikuyendera nthumwi zidapeza kuti nkhani monga kusankhana kochokera kukondera pakasankhidwe ka maudindo kusiyanitsa pakagawidwe ka zinthu ndi kupondereza zitukuko zomwe atsogoleri ena adayamba ndi zina mwa zinthu zomwe anthu akuona kuti ndi bwino aziyendetsa okha zinthu adatero chingota mlangizi wa mtsogoleri wa dziko lino pankhani za mgwirizano wa mdziko muno vuwa kaunda adati ndi cholinga cha mtsogoleri wa dziko lino peter mutharika kuti anthu azipereka maganizo awo kuti zinthu ziziyenda bwino kaunda adati mutharika adalumbira kuti adzalemekeza malamulo a dziko lino omwe amapereka mwayi kwa amalawi wolankhula zakukhosi kwawo mafumu nawo ayamikira zomwe lidachita bungwe la pac pokonza msonkhanowo ndi zomwe nthumwi zidagwirizanazo paramount chief chikulamayembe wa ku rumphi adati nzopatsa chidwi kuti boma ndi mabungwe akugwirizana pankhani yofuna kudzetsa umodzi ndi mtendere pomanga mfundo zoyendetsera nkhani zikuluzikulu monga imeneyi apa ndiye kuti zinthu ziyenda kusiyana nkuti anthu azingopanga phokoso lopanda tsogolo lake tionera kwa akuluakuluwo kuti akonza zotani adatero chikulamayembe koma malinga ndi chinsinga nkhaniyi ingaphweke amalawi atalangizidwa bwino momwe ulamuliro wotere ungayendere iye adati nzomvetsa chisoni ndi kuchititsa mantha kuti amalawi ena akungotsatira maganizo a anzawo chifukwa chosamvetsetsa iyitu si nkhani yaingono koma pakuoneka kuti anthu ambiri sakumvetsetsa mutuwu mmalo mwake angotsatirapo poti walankhulayo amamukhulupirira mpofunikanso kumasulira bwinobwino tanthauzo la nkhaniyi nkuphunzitsa amalawi kuti azipereka maganizo awo enieni adatero chinsinga iye adati ulamuliro wotere ndi njira yoyendetsera boma yomwe dziko limagawidwa mmagawo omwe amayendetsa okha ntchito za chitukuko koma ali pansi pa ulamuliro wa mtsogoleri mmodzi iye adati kutengera pamgongo nkhani yotereyi kukhoza kubweretsa kusamvana ndi chisokonezo pazinthu zingonongono muganizire apa dzikoli ndi lalingono kwambiri komanso njira zobweretsa ndalama nzochepa pofuna kugawa mpofunika kuunika bwinobwino mmene malire akhalire komanso kuti chigawo chanji chitenga chiyani adatero chinsinga mkulu wa bungwe la pac robert phiri adati msonkhano womwe bungweli lidakonza udakambirana zina mwa nkhani zoterezi msonkhanowo udachitika lolemba ndi lachiwiri mumzinda wa blantyre ndipo udabweretsa pamodzi akuluakulu a mnthambi za boma mabungwe oyima paokha ndi otsata mbiri ya dziko lino phiri adati zomwe adakambirana akuluakuluwo azitulutsa ndi kuzipereka kuboma ndi mabungwe kuti zipereke chithunzithunzi cha mmene angagwirire ntchito ndi anthu pankhaniyi mmbuyomu kafukufuku yemwe nyuzipepala ya the nation idachita adasonyeza kuti aphungu 61 mwa 100 alionse adati nkhaniyi itapita ku nyumba ya malamulo akhoza kuikana nyuzipepalayi itafunsa aphungu 122 mwa 193 75 adati angakane mfundoyi aphungu 17 adali asanaganize ngati angaivomereze kapena ayi pomwe aphungu 30 adati angavomereze za mfundoyi mchaka cha 2006 mtsogoleri wa dziko lino peter mutharika adanena kuti boma la mtunduwu likhoza kuthandiza pachitukuko cha dziko lino uku kudali msonkhano wounikira malamulo a dziko lino koma masiku ano mutharika amatsutsana ndi maganizowa ati kugawa dziko pamsonkhanowo padali a zipani zosiyanasiyana mafumu azipembedzo mabungwe omwe si aboma ndipo amayendetsa zokambiranazo ndi sipikala wakale wa nyumba ya malamulo henry chimunthu banda ndi wachiwiri kwa mtsogoleri wakale wa dziko lino justin malewezi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aSd_0iqwzEu",
        "outputId": "0d16fb52-61cd-4211-e455-604e405d8486"
      },
      "source": [
        "df.post[:].values"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' mwangonde khansala wachinyamata akamati achinyamata ndi atsogoleri a mawa ambiri amaganiza kuti izi ndi nkhambakamwa chabe koma achinyamata ena monga lusubilo mwangonde akukwaniritsa akupherezetsa mawuwa osati pongolota kuti adzakhala koma kutsogolera kumene chifukwa nthawi yawo yakwana dailes banda adacheza ndi mwangonde khansala wachinyama yemwe akuimira jumbo ward mumzinda wa mzuzu motere  chisale watuluka nkumangidwanso  sipakala waimitsa nyumba ya malamulo  pa wenela pasintha zedi ali ndi masomphenya mwangonde tikudziweni  ndine lusubilo mwangonde ndili ndi zaka 27 zakubadwa ndinabadwa mbanja la ana asanu ndipo ndine wachinayi kubadwa ndimachokera mmudzi mwa mwamalopa kwa paramount chief kyungu mboma la karonga sindili pabanja pakadalipano mbiri ya maphunziro anu ndi yotani maphunziro anga a pulaimale ndidachitira kusukula yapulaiveti ya viphya mumzinda wa mzuzu ndipo asekondale ndidachitira pa phwezi boys mboma la rumphi ndili ndi diploma ya accounting ndipo pakadalipano ndikupanga digiri komanso chartered accounting kusukulu ya malawi college of accountancy mca mudayamba bwanji zandale kuyambira ndili wachichepere zaka 12 ndakhala ndikukhala mumaudindo a utgogoleri ichi ndi china mwa zinthu zomwe zidandilimbikitsa kuti ndikhoza kudzapambana pazisankho koma chachikulu chomwe chidandichititsa kuti ndilowe ukhansala chidali chifukwa chakuti ndinkafuna kupereka mpata kwa anthu kuti azitha kuyankhula zakukhosi kwawo polimbikitsa demokalase ndi chitukuko ntchito mukugwira ndi zomwe munkayembekezera eya ndiponso ndinkayembekezera zambiri masomphenya anu ndi otani pandale ine ndine munthu wokhulupirira mulungu ndipo ndili ndi chikhulupiriro choti iye ndi amene adzandionetsere zomwe ndikuyera kuchita ndi tsogolo langa zinthu zina zomwe mumachita ndi chiyani pambali pa ukhansala ndikakhala sindikugwira ntchito yaukhansala ndimakhala ndikuchita bizinesi nthawi zina ndimakhala ndili kusukulu komwe ndikuchita maphuro anga a digiri kuonjezera pamenepo ndili ndi bungwe lomwe ndidayambitsa ndi anzanga ena la centre for participatory democracy lomwe limalimbikitsa demokalase zomwe mwakwanitsa ndi zotani ndathandiza kuti ntchito yopala misewu ya kudera la moyale itheke misewuyi yakhala nthawi yaitali osapalidwa ndidathandiziranso kuti ochita malonda ayambe kumanga mashopu anjerwa ndi kusiya kumangira matabwa kapena zigwagwa ndidakwanitsanso kukaimirira khonsolo ya mzuzu ku nyumba ya malamulo ndaonanso kuti ntchitoyi yandithandiza kusintha momwe ndimaonera zinthu komanso ndimakumana ndi anthu osiyanasiyana omwe amandiphunzitsa zinthu zambiri',\n",
              "       ' mcp siidakhutire ndi kalembera chipani cha malawi congress party mcp chati ngakhale ndime yachiwiri ya kalembera wa zisankho yayenda bwino poyerekeza ndi yoyamba mec iganizire zobwereranso mmaboma omwe yadutsamo kale kaamba koti anthu ambiri sadalembetse koma mkulu wa bungwe la malawi electoral commission mec jane ansah wati ndi wokhutira ndi mmene kalembera wayendera mgawo lachiwiri  chakwera akwanitse malonjezohrdc  masankhidwe a nduna autsa mapiri pa chigwa  malonjezo ayamba kuoneka ansah zinthu zayenda bwino kalembera wa mgawoli amachitikira mmaboma a dowa ntchisi mchinji ndi nkhotakota malingana ndi lipoti lomwe mec yatulutsa mwa anthu 1 048 080 omwe limayembekezera kulembetsa anthu 875 138 ndiwo alembetsa chiwerengerochi chikutanthauza kuti mwa anthu 100 aliwonse omwe amayenera kulembetsa 83 ndiwo alembetsa zomwe zachititsa mlembi wa mcp maurice munthali kupempha mec kuti ibwererenso mmabomawo pali chosekerera apa tiyenera kuyandikira kwenikweni ku chiwerengero cha anthu omwe tidayenera kuwalembetsa koma zomwe zachitika apa zikusonyeza poyera kuti anthu ambiri sadalembetse choncho mec iyenera kubwereranso mmabomawo adatero munthali mlembiyu adati mu ufulu wa demokalase ngakhale kusiya munthu mmodzi zimakhala zodandaulitsa mkulu wa bungwe la human rights defenders timothy mtambo akugwirizana ndi mcp kuti kalemberayo adzachitikenso kaamba koti munthu aliyense ali ndi ufulu wovota mkulu wa bungwe la national initiative for civic education nice trust ollen mwalubunju adati zinthu mgawo lachiwiri zasintha kwambiri poyerekeza ndi loyamba pali kusintha kwakukulu chifukwa mgawo loyamba timanena za anthu 73 pa anthu 100 aliwonse koma pano tikunena za anthu 83 pa anthu 100 aliwonse izi zikutanthauza kuti zinthu zikusintha adatero mwalubunju pazaganizo lobwereranso mmaboma momwe kalemberayu wachitika kale mwalubunju adati mpofunika kudikira kaye kuti mec iwone mmene zinthu zitayendere mmaboma ena malingana ndi kalata ya mec yomwe yasayinidwa ndi woyanganira zisankho sam alfandika mwa anthu onse omwe alembetsa mgawo lachiwiriri 462 925 ndi amayi ndipo 411 706 ndi abambo ansah adati zinthu zasintha kwambiri mgawoli poyerekeza ndi mmene zidaliri mgawo loyamba mmaboma a kasungu dedza ndi salima mavuto a akulu omwe takumana nawo ndi kuwonongeka kwa zipangizo zogwirira ntchito kusowa kwa dizilo wa ma generator athu komanso zipangizo zoyendera mphamvu ya dzuwa sizimagwira bwino ntchito moyenera potengera ndi mmene nyengo ilili mavutowa tawapezera njira zake moti kukubwera konseku anthu ayembekezere kalembera wabwino iye adatero ansah adati mec siidapange chiganizo pa nkhani yobwereranso mmaboma momwe yadutsamo kale',\n",
              "       'bungwe la manepo lapempha boma liganizire anthu achikulire pa mliri wa coronavirus bungwe loyanganira anthu achikulire la malawi network of older persons organisation manepo lapempha boma kuti liganizire anthu achikulire pomwe likuyika ndondomeko zokhudza nthenda ya covid-19 kudzera mu kalata yomwe bungwe la manepo latulutsa mkulu wa bungweli andrew kavala wati kusowa kwa malamulo okhazikika oteteza anthu achikulire kukupitilira kuyika anthuwa pa chiopsyezo cha nkhanza zosiyanasiyana iye wapemphanso boma ndi mabungwe kuti pakhale njira zabwino zofalitsira mauthenga a covid-19 kuti nawo anthu achikulire afikiridwe ndi mauthenga okhudza njira zabwino zopewera mliriwu mfundo za kuno ku malawi zimasala anthu achikulire ndipo ichi ndi chiopsezo chachikulu ku matenda a covid-19 kwa anthu amenewa anatero a kavala iwo apempha boma kuti liyike malamulo amphamvu oteteza anthu achikulire kwa anthu omwe amawaphwanyira ufulu ',\n",
              "       ...,\n",
              "       ' mawu supports non-fiction writers the malawi writer union mawu has thrown its weight behind the establishment of a separate writers body the malawi union of academic and non-fiction authors muana muana is the third body of writers after mawu and the poetry association of malawi pam  chisale watuluka nkumangidwanso  sipakala waimitsa nyumba ya malamulo  pa wenela pasintha zedi sambalikagwa mvona with support from the norwegian non-fiction writers and translators association the new body was established to promote non-fiction and academic research and publication after noticing that mawu and pam were mainly promoting fiction writing as mawu we are happy with the establishment of the new body in fact it did not come as a surprise as we have been part of a series meetings that have given birth to muana explained mawu president sambalikagwa mvona he said despite that it has affected the mawu membership he is happy as the establishment of a new body is a step in the right direction we have lost a few of our members but in the positive because they have formed an equally important body this is good for the nation and we are empowering others to grow wings he said muana is headed by max iphani who is book editor at the malawi institute of education some of muanas goals include ensuring that there is sound professional and legal relationships between authors and publishers assist authors in publishing contracts as well as striving to build capacity of non-fiction and academic authors and lobby for increased numbers of malawian textbooks in institutions of learning',\n",
              "       ' tame mwawa phwete ndiye kudya kwake sewero la tikuferanji ndi limodzi mwa masewero omwe amapereka phunziro kwa anthu pazochitika mmoyo wa tsiku ndi tsiku komanso ndi msangulutso kwa anthu ambiri seweroli limaonetsedwa pakanema komanso kumveka pawailesi ya mbc steven pembamoyo adachita chidwi ndi mmodzi mwa omwe amachita nawo seweroli tame mwawa yemwe ambiri amamudziwa kuti chiphwanya museweromo ndipo adacheza naye motere  pa wenela pasintha zedi  anatchereza  tidakumana ku sukulu ku chiradzulu mwawa ndidabadwa wazisudzo ndikudziwe mnzanga ndine tame mwawa ndimakhala ku machinjiri ku blantyre koma kwathu nku chiradzulu mmudzi mwa kambalame t/a mpama udabadwa mchaka chanji ndidabadwa pa 26 october 1977 ndipo ndine woyamba mbanja la ana 7 amuna 5 ndi asungwana awiri mbiri yako pazisudzo ndi yotani ndikhoza kunena kuti ndidabadwa wazisudzo kale abale anga amandiuza kuti ndili wamngono ndikadziongola kapena ndikamalira anthu amandiunjirira nkumaseka ndipo makolo anga adadziwiratu kuti ndidzakhala msangalatsi kusukulu anzanga ngakhalenso aphunzitsi ankachita kudziwa kuti tame wabwera zilango ndiye zidali zosatha nthawi zina ndinkalembedwa pa anthu olongolola koma pomwe sindidapite kusukulu nkomwe pachikondwerero chokumbukira ufulu wa dziko ndinkapanga nawo zisudzo ndipo malipiro ake adali fanta ndi mpunga wa nyama ndinkapanganso sewero la ambuye yesu udapezeka bwanji musewero la tikuferanji nthawi ina yake ankakajambula seweroli pafupi ndi kwathu ndiye penapake pamafunika singanga koma munthu amasowa tsono ine ndidadzipereka kuti ndiyesere nkuchita bwino basi kulowa mseweroli kudali kumeneko panthawi imeneyo ndidadziwana ndi akuluakulu ena azisudzo monga frank yalu nginde yemwe adanditenga kukalowa gulu lake la zisudzo lotchedwa kasupe arts theatre pano ndidadziwika kwambiri moti ndimapezeka mmagulu azisudzo osiyanasiyana monga kwathu komanso mumafilimi osiyanasiyana imodzi mwa mafilimu omwe ndilimo ndi ya chinganingani yomwe ikuoneka pakanema ya malawi komanso ndidayambitsa nawo pologalamu ya phwete pa kanema yomweyi pawayilesi ndimapanga nawo sewero la sabata ino dzina la chiphwanya lidayamba bwanji kumudzi kwathu ku chiradzulu kuli mkulu wina dzina lake chiphwanya yemwe ndi wolongolola komanso wosachedwa kupsa mtima ndiye nditaona malo omwe ndimapatsidwa mmasewero ambiri ndidaona kuti dzinali ndi londiyenera nzoona kuti pakhomo pako udadzala zikho zambiri eya ndimadziwiratu mbali zomwe anzanga amakonda kundipatsa pazisudzo motero ndidadzala zikho zambiri komanso mikanda pakhomo panga ili mbweee moti anthu ena amaona ngati ndimapangadi zausinganga',\n",
              "       ' pac iunguza za boma la chifedulo nthumwi zomwe zimakumana mumzinda wa blantyre kukambirana za nkhani yakuti zigawo za dziko lino zizikhala ndi mtsogoleri wakewake pansi pa mtsogoleri wa dziko zati nkhaniyi kuti iyende bwino mpofunika kusintha malamulo ena mfundoyi ikugwirizana ndi zomwe adanena mphunzitsi wa za ndale kusukulu ya ukachenjede ya chancellor college blessings chinsinga kuti popanda kuunika malamulo nkhaniyi ikhoza kudzetsa chisokonezo  chisale watuluka nkumangidwanso  sipakala waimitsa nyumba ya malamulo  chakwera akwanitse malonjezohrdc choyamba tiunike kuti malamulo athu akutinji chifukwa mukhoza kukhala ndi zigawo zodziyimira pazokha zomwe zingamakolanenso chifukwa cha malamulo omwe mukutsata adatero chinsinga msonkhanowo udakonzedwa ndi bungwe la mipingo la public affairs committee pac ndipo cholinga chake chidali kuunika chomwe chidayambitsa nkhaniyi ndi kukambirana momwe ingayendere malinga ndi wapampando wa bungwe la pac mbusa felix chingota nthumwi za kumsonkhanowo zidapeza kuti nkhaniyo idachokera pakusamvetsetsana pa momwe zinthu zina zikuyendera nthumwi zidapeza kuti nkhani monga kusankhana kochokera kukondera pakasankhidwe ka maudindo kusiyanitsa pakagawidwe ka zinthu ndi kupondereza zitukuko zomwe atsogoleri ena adayamba ndi zina mwa zinthu zomwe anthu akuona kuti ndi bwino aziyendetsa okha zinthu adatero chingota mlangizi wa mtsogoleri wa dziko lino pankhani za mgwirizano wa mdziko muno vuwa kaunda adati ndi cholinga cha mtsogoleri wa dziko lino peter mutharika kuti anthu azipereka maganizo awo kuti zinthu ziziyenda bwino kaunda adati mutharika adalumbira kuti adzalemekeza malamulo a dziko lino omwe amapereka mwayi kwa amalawi wolankhula zakukhosi kwawo mafumu nawo ayamikira zomwe lidachita bungwe la pac pokonza msonkhanowo ndi zomwe nthumwi zidagwirizanazo paramount chief chikulamayembe wa ku rumphi adati nzopatsa chidwi kuti boma ndi mabungwe akugwirizana pankhani yofuna kudzetsa umodzi ndi mtendere pomanga mfundo zoyendetsera nkhani zikuluzikulu monga imeneyi apa ndiye kuti zinthu ziyenda kusiyana nkuti anthu azingopanga phokoso lopanda tsogolo lake tionera kwa akuluakuluwo kuti akonza zotani adatero chikulamayembe koma malinga ndi chinsinga nkhaniyi ingaphweke amalawi atalangizidwa bwino momwe ulamuliro wotere ungayendere iye adati nzomvetsa chisoni ndi kuchititsa mantha kuti amalawi ena akungotsatira maganizo a anzawo chifukwa chosamvetsetsa iyitu si nkhani yaingono koma pakuoneka kuti anthu ambiri sakumvetsetsa mutuwu mmalo mwake angotsatirapo poti walankhulayo amamukhulupirira mpofunikanso kumasulira bwinobwino tanthauzo la nkhaniyi nkuphunzitsa amalawi kuti azipereka maganizo awo enieni adatero chinsinga iye adati ulamuliro wotere ndi njira yoyendetsera boma yomwe dziko limagawidwa mmagawo omwe amayendetsa okha ntchito za chitukuko koma ali pansi pa ulamuliro wa mtsogoleri mmodzi iye adati kutengera pamgongo nkhani yotereyi kukhoza kubweretsa kusamvana ndi chisokonezo pazinthu zingonongono muganizire apa dzikoli ndi lalingono kwambiri komanso njira zobweretsa ndalama nzochepa pofuna kugawa mpofunika kuunika bwinobwino mmene malire akhalire komanso kuti chigawo chanji chitenga chiyani adatero chinsinga mkulu wa bungwe la pac robert phiri adati msonkhano womwe bungweli lidakonza udakambirana zina mwa nkhani zoterezi msonkhanowo udachitika lolemba ndi lachiwiri mumzinda wa blantyre ndipo udabweretsa pamodzi akuluakulu a mnthambi za boma mabungwe oyima paokha ndi otsata mbiri ya dziko lino phiri adati zomwe adakambirana akuluakuluwo azitulutsa ndi kuzipereka kuboma ndi mabungwe kuti zipereke chithunzithunzi cha mmene angagwirire ntchito ndi anthu pankhaniyi mmbuyomu kafukufuku yemwe nyuzipepala ya the nation idachita adasonyeza kuti aphungu 61 mwa 100 alionse adati nkhaniyi itapita ku nyumba ya malamulo akhoza kuikana nyuzipepalayi itafunsa aphungu 122 mwa 193 75 adati angakane mfundoyi aphungu 17 adali asanaganize ngati angaivomereze kapena ayi pomwe aphungu 30 adati angavomereze za mfundoyi mchaka cha 2006 mtsogoleri wa dziko lino peter mutharika adanena kuti boma la mtunduwu likhoza kuthandiza pachitukuko cha dziko lino uku kudali msonkhano wounikira malamulo a dziko lino koma masiku ano mutharika amatsutsana ndi maganizowa ati kugawa dziko pamsonkhanowo padali a zipani zosiyanasiyana mafumu azipembedzo mabungwe omwe si aboma ndipo amayendetsa zokambiranazo ndi sipikala wakale wa nyumba ya malamulo henry chimunthu banda ndi wachiwiri kwa mtsogoleri wakale wa dziko lino justin malewezi'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk63EZdUwXlR",
        "outputId": "8cfa1347-5f1a-4a29-cd7d-40aa47a0fc79"
      },
      "source": [
        "max_fatures = 15000\n",
        "\n",
        "# Max number of words in each complaint.\n",
        "\n",
        "\n",
        "#tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ', filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789', lower=True)\n",
        "tokenizer.fit_on_texts(df['post'].values)\n",
        "X_allw = list(tokenizer.texts_to_sequences(df.post[:].values,))\n",
        "X_all = list(pad_sequences(X_allw,dtype='float'))\n",
        "print('Found %s unique tokens.' % len(X_all))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1436 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMr8Vt7kF57G"
      },
      "source": [
        "#pad_lines=list(pad_sequences(lines,dtype='float',value=0.0,padding=\"post\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTCXu4ePCQIE"
      },
      "source": [
        "X_all=[list(i) for i in X_all ]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU7pEsqnGxm1",
        "outputId": "f0bf76ea-f7b8-4f17-86c2-e11ebb54869e"
      },
      "source": [
        "type(X_all)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJgdt5-f9l5X"
      },
      "source": [
        "xtestp=0.80\n",
        "divi=int(len(X_all)*xtestp)\n",
        "X=X_all[:divi]\n",
        "X_test=X_all[divi:]\n",
        "yall=list(df.label_index)\n",
        "y=yall[:divi]\n",
        "y_test=yall[divi:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vKFICctwlmX",
        "outputId": "a1888ee3-6fec-40b8-d73e-aed0d9707ab7"
      },
      "source": [
        "len(X[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVZGbQD71Iiv",
        "outputId": "7e9ba596-a977-491b-c472-70536e60b83d"
      },
      "source": [
        "type(X[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y66egjuhEZQN"
      },
      "source": [
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout,Embedding, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta,Adagrad,Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhHYxCHIJZ1b"
      },
      "source": [
        "fname=\"_model_1_\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FrIWOR1A8Gw",
        "outputId": "c06faada-eddb-4b55-c2ff-a2c30ef3abb9"
      },
      "source": [
        "clear_session()\n",
        "\n",
        "\n",
        "\n",
        "input_size=max_fatures\n",
        "input_len=len(X[0])\n",
        "print(input_len)\n",
        "output_size=20\n",
        "drop_frac0=0.6 \n",
        "drop_frac1=0.6\n",
        "\n",
        "\n",
        "\n",
        "input1=Input(shape=(input_len,),)\n",
        "embed=Embedding(input_size,14,input_length=input_len,mask_zero=True,trainable=True)(input1)\n",
        "lstm1=LSTM(input_len,dropout=0.61,return_sequences=False,return_state=False, go_backwards=True)(embed)\n",
        "#flatt=Flatten()(lstm1)\n",
        "d1=Dense(520,activation=\"relu\")(lstm1)\n",
        "drop0=Dropout(drop_frac0)(d1)\n",
        "\n",
        "d2=Dense(80,activation=\"relu\")(drop0)\n",
        "drop1=Dropout(drop_frac1)(d2)\n",
        "\n",
        "\n",
        "\n",
        "pred=Dense(output_size,activation=\"softmax\")(drop1)\n",
        "\n",
        "model = Model(inputs=input1, outputs=pred)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=[\"accuracy\"])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3YuhrKQKocK",
        "outputId": "2ace7953-7be5-465e-e87e-00a62bc05e3e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 828)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 828, 14)           210000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 828)               2792016   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 520)               431080    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 520)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 80)                41680     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                1620      \n",
            "=================================================================\n",
            "Total params: 3,476,396\n",
            "Trainable params: 3,476,396\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDA1yOVREuFA"
      },
      "source": [
        "callbacks = [#callback_LR,\n",
        "       \n",
        "        ModelCheckpoint(filepath=fname+\"_{loss:.5f}_{val_accuracy:.5f}_.hdf5\", monitor='val_accuracy',\n",
        "                        verbose=2, save_best_only=True, mode='max')]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "301Bt5haEpUZ",
        "outputId": "5ee298ce-0c75-4ed5-847d-c88dc38195c8"
      },
      "source": [
        "history = model.fit( X,y,validation_data=(X_test,y_test), \n",
        "                        epochs=150, \n",
        "                        batch_size=132,\n",
        "                        \n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks,\n",
        "                              \n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "9/9 [==============================] - 20s 2s/step - loss: 3.8528 - accuracy: 0.1186 - val_loss: 2.8727 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.17708, saving model to _model_1__4.05652_0.17708_.hdf5\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 3.2316 - accuracy: 0.0952 - val_loss: 2.8600 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.17708\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.9360 - accuracy: 0.1101 - val_loss: 2.7915 - val_accuracy: 0.1007\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.17708\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.8298 - accuracy: 0.1169 - val_loss: 2.6947 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.17708\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.8690 - accuracy: 0.1533 - val_loss: 2.7059 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.17708\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.7738 - accuracy: 0.1742 - val_loss: 2.6566 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.17708\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.7521 - accuracy: 0.1648 - val_loss: 2.6634 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.17708\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.7062 - accuracy: 0.1827 - val_loss: 2.6507 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.17708\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.7031 - accuracy: 0.1758 - val_loss: 2.6277 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.17708\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6745 - accuracy: 0.1684 - val_loss: 2.6658 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.17708\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6540 - accuracy: 0.1834 - val_loss: 2.6226 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.17708\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6684 - accuracy: 0.1838 - val_loss: 2.6245 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.17708\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6409 - accuracy: 0.2033 - val_loss: 2.6295 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.17708\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6609 - accuracy: 0.1851 - val_loss: 2.6212 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.17708\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6392 - accuracy: 0.1882 - val_loss: 2.6271 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.17708\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.5966 - accuracy: 0.1992 - val_loss: 2.6150 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.17708\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.6226 - accuracy: 0.1939 - val_loss: 2.6105 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.17708\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.5203 - accuracy: 0.1986 - val_loss: 2.6285 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.17708\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.4589 - accuracy: 0.1849 - val_loss: 2.6441 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.17708\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.4049 - accuracy: 0.1887 - val_loss: 2.6323 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.17708\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.3375 - accuracy: 0.1966 - val_loss: 2.6799 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.17708\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.2137 - accuracy: 0.2143 - val_loss: 2.7409 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.17708\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.2051 - accuracy: 0.2321 - val_loss: 2.7020 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.17708\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.1292 - accuracy: 0.2563 - val_loss: 2.7904 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.17708\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.1126 - accuracy: 0.2514 - val_loss: 2.8557 - val_accuracy: 0.1875\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.17708 to 0.18750, saving model to _model_1__2.09688_0.18750_.hdf5\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.0245 - accuracy: 0.2868 - val_loss: 3.0479 - val_accuracy: 0.1979\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.18750 to 0.19792, saving model to _model_1__2.04333_0.19792_.hdf5\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.0116 - accuracy: 0.2757 - val_loss: 3.0969 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.19792\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 2.0237 - accuracy: 0.2700 - val_loss: 3.1779 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.19792\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.9674 - accuracy: 0.2932 - val_loss: 3.1291 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.19792\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.9052 - accuracy: 0.3100 - val_loss: 3.1346 - val_accuracy: 0.1910\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.19792\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.9393 - accuracy: 0.3041 - val_loss: 3.1344 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.19792\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.8989 - accuracy: 0.3193 - val_loss: 3.1978 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.19792\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 14s 2s/step - loss: 1.8443 - accuracy: 0.3420 - val_loss: 3.5022 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.19792\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.8410 - accuracy: 0.3425 - val_loss: 3.3727 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.19792\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.8058 - accuracy: 0.3386 - val_loss: 3.4040 - val_accuracy: 0.1875\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.19792\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.7590 - accuracy: 0.3664 - val_loss: 3.8842 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.19792\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.6958 - accuracy: 0.3791 - val_loss: 3.4411 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.19792\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.8253 - accuracy: 0.3486 - val_loss: 3.3519 - val_accuracy: 0.1319\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.19792\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.7997 - accuracy: 0.3455 - val_loss: 3.5246 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.19792\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.7151 - accuracy: 0.3741 - val_loss: 3.8822 - val_accuracy: 0.1528\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.19792\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.7018 - accuracy: 0.3764 - val_loss: 3.7827 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.19792\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6898 - accuracy: 0.3842 - val_loss: 3.8216 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.19792\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.6969 - accuracy: 0.3835 - val_loss: 3.8303 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.19792\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.7448 - accuracy: 0.3759 - val_loss: 3.7018 - val_accuracy: 0.2049\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.19792 to 0.20486, saving model to _model_1__1.72281_0.20486_.hdf5\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6770 - accuracy: 0.3641 - val_loss: 4.2995 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.20486\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6512 - accuracy: 0.3802 - val_loss: 3.6500 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.20486\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6278 - accuracy: 0.4001 - val_loss: 4.0942 - val_accuracy: 0.1806\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.20486\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5520 - accuracy: 0.4243 - val_loss: 4.3285 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.20486\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6577 - accuracy: 0.3917 - val_loss: 3.7950 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.20486\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.7357 - accuracy: 0.3569 - val_loss: 3.6100 - val_accuracy: 0.1562\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.20486\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6573 - accuracy: 0.4008 - val_loss: 3.9424 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.20486\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.6641 - accuracy: 0.4051 - val_loss: 4.0533 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.20486\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5937 - accuracy: 0.4014 - val_loss: 4.2964 - val_accuracy: 0.1562\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.20486\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5641 - accuracy: 0.4143 - val_loss: 3.9311 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.20486\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5446 - accuracy: 0.4133 - val_loss: 4.1155 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.20486\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5621 - accuracy: 0.3895 - val_loss: 3.9291 - val_accuracy: 0.1424\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.20486\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5282 - accuracy: 0.4032 - val_loss: 4.1292 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.20486\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5062 - accuracy: 0.4309 - val_loss: 4.3943 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.20486\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5024 - accuracy: 0.4334 - val_loss: 4.2152 - val_accuracy: 0.1319\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.20486\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.4629 - accuracy: 0.4387 - val_loss: 4.3530 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.20486\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.4753 - accuracy: 0.4362 - val_loss: 4.5748 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.20486\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.4612 - accuracy: 0.4410 - val_loss: 4.2424 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.20486\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3605 - accuracy: 0.4899 - val_loss: 4.6634 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.20486\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3881 - accuracy: 0.4383 - val_loss: 4.4878 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.20486\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3456 - accuracy: 0.4591 - val_loss: 4.3534 - val_accuracy: 0.1562\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.20486\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.3803 - accuracy: 0.4773 - val_loss: 4.5609 - val_accuracy: 0.1528\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.20486\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.4120 - accuracy: 0.4401 - val_loss: 4.6884 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.20486\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.5006 - accuracy: 0.4354 - val_loss: 4.3192 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.20486\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 16s 2s/step - loss: 1.4869 - accuracy: 0.4288 - val_loss: 4.8265 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.20486\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3876 - accuracy: 0.4317 - val_loss: 4.4918 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.20486\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3672 - accuracy: 0.4699 - val_loss: 4.6938 - val_accuracy: 0.1806\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.20486\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3884 - accuracy: 0.4598 - val_loss: 4.6907 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.20486\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.4083 - accuracy: 0.4473 - val_loss: 4.6452 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.20486\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3335 - accuracy: 0.4697 - val_loss: 4.6426 - val_accuracy: 0.1493\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.20486\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.4339 - accuracy: 0.4472 - val_loss: 4.4311 - val_accuracy: 0.1632\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.20486\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3431 - accuracy: 0.4628 - val_loss: 5.1652 - val_accuracy: 0.1597\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.20486\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.3735 - accuracy: 0.4654 - val_loss: 4.7768 - val_accuracy: 0.1701\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.20486\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.2569 - accuracy: 0.5025 - val_loss: 5.0255 - val_accuracy: 0.1736\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.20486\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 15s 2s/step - loss: 1.2607 - accuracy: 0.5013 - val_loss: 5.0530 - val_accuracy: 0.1562\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.20486\n",
            "Epoch 80/150\n",
            "2/9 [=====>........................] - ETA: 11s - loss: 1.0650 - accuracy: 0.5587"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}